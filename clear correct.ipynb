{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\envs\\ped\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Ali\\Anaconda3\\envs\\ped\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os , itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':1,\n",
    "    'input_size':224,\n",
    "    'resize_scale':224,\n",
    "    'crop_size':224,\n",
    "    'fliplr':True,\n",
    "    #model params\n",
    "    'num_epochs':500,\n",
    "    'decay_epoch':100,\n",
    "    'ngf':32,   #number of generator filters\n",
    "    'ndf':64,   #number of discriminator filters\n",
    "    'num_resnet':6, #number of resnet blocks\n",
    "    'lrG':0.0002,    #learning rate for generator\n",
    "    'lrD':0.0002,    #learning rate for discriminator\n",
    "    'beta1':0.5 ,    #beta1 for Adam optimizer\n",
    "    'beta2':0.999 ,  #beta2 for Adam optimizer\n",
    "    'lambdaA':10 ,   #lambdaA for cycle loss\n",
    "    'lambdaB':10  ,  #lambdaB for cycle loss\n",
    "}\n",
    "\n",
    "data_dir = 'Data'\n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "def plot_train_result(real_image, gen_image, recon_image, epoch, save=False,  show=True, fig_size=(15, 15)):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=fig_size)\n",
    "    imgs = [to_np(real_image[0]), to_np(gen_image[0]), to_np(recon_image[0]),\n",
    "            to_np(real_image[1]), to_np(gen_image[1]), to_np(recon_image[1])]\n",
    "    for ax, img in zip(axes.flatten(), imgs):\n",
    "        ax.axis('off')\n",
    "        #ax.set_adjustable('box-forced')\n",
    "        # Scale to 0-255\n",
    "        img = img.squeeze()\n",
    "        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n",
    "        ax.imshow(img, cmap=None, aspect='equal')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    title = 'Epoch {0}'.format(epoch + 1)\n",
    "    fig.text(0.5, 0.04, title, ha='center')\n",
    "\n",
    "    # save figure\n",
    "    if save:\n",
    "        save_fn = 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images.data:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, image_dir, subfolder='train', transform=None, resize_scale=None, crop_size=None, fliplr=False):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.resize_scale = resize_scale\n",
    "        self.crop_size = crop_size\n",
    "        self.fliplr = fliplr\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load Image\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        img = Image.open(img_fn).convert('RGB')\n",
    "\n",
    "        # preprocessing\n",
    "        if self.resize_scale:\n",
    "            img = img.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n",
    "\n",
    "        if self.crop_size:\n",
    "            x = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
    "            y = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
    "            img = img.crop((x, y, x + self.crop_size, y + self.crop_size))\n",
    "        if self.fliplr:\n",
    "            if random.random() < 0.5:\n",
    "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,activation='relu',batch_norm=True):\n",
    "        super(ConvBlock,self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(input_size,output_size,kernel_size,stride,padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2,True)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out\n",
    "            \n",
    "class DeconvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,output_padding=1,activation='relu',batch_norm=True):\n",
    "        super(DeconvBlock,self).__init__()\n",
    "        self.deconv = torch.nn.ConvTranspose2d(input_size,output_size,kernel_size,stride,padding,output_padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.deconv(x))\n",
    "        else:\n",
    "            out = self.deconv(x)\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out\n",
    "\n",
    "class ResnetBlock(torch.nn.Module):\n",
    "    def __init__(self,num_filter,kernel_size=3,stride=1,padding=0):\n",
    "        super(ResnetBlock,self).__init__()\n",
    "        conv1 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n",
    "        conv2 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n",
    "        bn = torch.nn.InstanceNorm2d(num_filter)\n",
    "        relu = torch.nn.ReLU(True)\n",
    "        pad = torch.nn.ReflectionPad2d(1)\n",
    "        \n",
    "        self.resnet_block = torch.nn.Sequential(\n",
    "            pad,\n",
    "            conv1,\n",
    "            bn,\n",
    "            relu,\n",
    "            pad,\n",
    "            conv2,\n",
    "            bn\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        out = self.resnet_block(x)\n",
    "        return out\n",
    "        \n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self,input_dim,num_filter,output_dim,num_resnet):\n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        #Reflection padding\n",
    "        self.pad = torch.nn.ReflectionPad2d(3)\n",
    "        #Encoder\n",
    "        self.conv1 = ConvBlock(input_dim,num_filter,kernel_size=7,stride=1,padding=0)\n",
    "        self.conv2 = ConvBlock(num_filter,num_filter*2)\n",
    "        self.conv3 = ConvBlock(num_filter*2,num_filter*4)\n",
    "        #Resnet blocks\n",
    "        self.resnet_blocks = []\n",
    "        for i in range(num_resnet):\n",
    "            self.resnet_blocks.append(ResnetBlock(num_filter*4))\n",
    "        self.resnet_blocks = torch.nn.Sequential(*self.resnet_blocks)\n",
    "        #Decoder\n",
    "        self.deconv1 = DeconvBlock(num_filter*4,num_filter*2)\n",
    "        self.deconv2 = DeconvBlock(num_filter*2,num_filter)\n",
    "        self.deconv3 = ConvBlock(num_filter,output_dim,kernel_size=7,stride=1,padding=0,activation='tanh',batch_norm=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #Encoder\n",
    "        enc1 = self.conv1(self.pad(x))\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        #Resnet blocks\n",
    "        res = self.resnet_blocks(enc3)\n",
    "        #Decoder\n",
    "        dec1 = self.deconv1(res)\n",
    "        dec2 = self.deconv2(dec1)\n",
    "        out = self.deconv3(self.pad(dec2))\n",
    "        return out\n",
    "    \n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
    "            if isinstance(m,DeconvBlock):\n",
    "                torch.nn.init.normal_(m.deconv.weight,mean,std)\n",
    "            if isinstance(m,ResnetBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
    "                torch.nn.init.constant_(m.conv.bias,0)\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self,input_dim,num_filter,output_dim):\n",
    "        super(Discriminator,self).__init__()\n",
    "        conv1 = ConvBlock(input_dim,num_filter,kernel_size=4,stride=2,padding=1,activation='lrelu',batch_norm=False)\n",
    "        conv2 = ConvBlock(num_filter,num_filter*2,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
    "        conv3 = ConvBlock(num_filter*2,num_filter*4,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
    "        conv4 = ConvBlock(num_filter*4,num_filter*8,kernel_size=4,stride=1,padding=1,activation='lrelu')\n",
    "        conv5 = ConvBlock(num_filter*8,output_dim,kernel_size=4,stride=1,padding=1,activation='no_act',batch_norm=False)\n",
    "        self.conv_blocks = torch.nn.Sequential(\n",
    "            conv1,\n",
    "            conv2,\n",
    "            conv3,\n",
    "            conv4,\n",
    "            conv5\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        out = self.conv_blocks(x)\n",
    "        return out\n",
    "        \n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight.data,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_16468\\2623136697.py:19: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img = img.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=params['input_size']),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "train_data_A = DatasetFromFolder(data_dir, subfolder='trainA', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "train_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A, batch_size=params['batch_size'], shuffle=True)\n",
    "train_data_B = DatasetFromFolder(data_dir, subfolder='trainB', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=params['batch_size'], shuffle=True)\n",
    "#Load test data\n",
    "test_data_A = DatasetFromFolder(data_dir, subfolder='testA', transform=transform)\n",
    "test_data_loader_A = torch.utils.data.DataLoader(dataset=test_data_A, batch_size=params['batch_size'], shuffle=False)\n",
    "test_data_B = DatasetFromFolder(data_dir, subfolder='testB', transform=transform)\n",
    "test_data_loader_B = torch.utils.data.DataLoader(dataset=test_data_B, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get specific test images\n",
    "test_real_A_data = train_data_A.__getitem__(11).unsqueeze(0) # Convert to 4d tensor (BxNxHxW)\n",
    "test_real_B_data = train_data_B.__getitem__(9).unsqueeze(0)\n",
    "#print(test_real_A_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Model \n",
    "G_A = Generator(3, params['ngf'], 3, params['num_resnet']).cuda() # input_dim, num_filter, output_dim, num_resnet\n",
    "G_B = Generator(3, params['ngf'], 3, params['num_resnet']).cuda()\n",
    "\n",
    "\n",
    "D_A = Discriminator(3, params['ndf'], 1).cuda() # input_dim, num_filter, output_dim\n",
    "D_B = Discriminator(3, params['ndf'], 1).cuda()\n",
    "\n",
    "#G_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "#G_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "G_optimizer = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=params['lrG'], betas=(params['beta1'], params['beta2']))\n",
    "D_A_optimizer = torch.optim.Adam(D_A.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n",
    "D_B_optimizer = torch.optim.Adam(D_B.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n",
    "\n",
    "MSE_Loss = torch.nn.MSELoss().cuda()\n",
    "L1_Loss = torch.nn.L1Loss().cuda()\n",
    "\n",
    "# # Training GAN\n",
    "D_A_avg_losses = []\n",
    "D_B_avg_losses = []\n",
    "G_A_avg_losses = []\n",
    "G_B_avg_losses = []\n",
    "cycle_A_avg_losses = []\n",
    "cycle_B_avg_losses = []\n",
    "\n",
    "# Generated image pool\n",
    "num_pool = 50\n",
    "fake_A_pool = ImagePool(num_pool)\n",
    "fake_B_pool = ImagePool(num_pool)\n",
    "\n",
    "step = 0\n",
    "for epoch in range(params['num_epochs']):\n",
    "    D_A_losses = []\n",
    "    D_B_losses = []\n",
    "    G_A_losses = []\n",
    "    G_B_losses = []\n",
    "    cycle_A_losses = []\n",
    "    cycle_B_losses = []\n",
    "    \n",
    "    # Learing rate decay \n",
    "    if(epoch + 1) > params['decay_epoch']:\n",
    "        D_A_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n",
    "        D_B_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n",
    "        G_optimizer.param_groups[0]['lr'] -= params['lrG'] / (params['num_epochs'] - params['decay_epoch'])\n",
    "        \n",
    "    \n",
    "    # training \n",
    "    for i, (real_A, real_B) in enumerate(zip(train_data_loader_A, train_data_loader_B)):\n",
    "        \n",
    "        # input image data\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "        \n",
    "        # -------------------------- train generator G --------------------------\n",
    "        # A --> B\n",
    "        fake_B = G_A(real_A)\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        G_A_loss = MSE_Loss(D_B_fake_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # forward cycle loss\n",
    "        recon_A = G_B(fake_B)\n",
    "        cycle_A_loss = L1_Loss(recon_A, real_A) * params['lambdaA']\n",
    "        \n",
    "        # B --> A\n",
    "        fake_A = G_B(real_B)\n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        G_B_loss = MSE_Loss(D_A_fake_decision, Variable(torch.ones(D_A_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # backward cycle loss\n",
    "        recon_B = G_A(fake_A)\n",
    "        cycle_B_loss = L1_Loss(recon_B, real_B) * params['lambdaB']\n",
    "        \n",
    "        # Back propagation\n",
    "        G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # -------------------------- train discriminator D_A --------------------------\n",
    "        D_A_real_decision = D_A(real_A)\n",
    "        D_A_real_loss = MSE_Loss(D_A_real_decision, Variable(torch.ones(D_A_real_decision.size()).cuda()))\n",
    "        \n",
    "        fake_A = fake_A_pool.query(fake_A)\n",
    "        \n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        D_A_fake_loss = MSE_Loss(D_A_fake_decision, Variable(torch.zeros(D_A_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # Back propagation\n",
    "        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "        D_A_optimizer.zero_grad()\n",
    "        D_A_loss.backward()\n",
    "        D_A_optimizer.step()\n",
    "        \n",
    "        # -------------------------- train discriminator D_B --------------------------\n",
    "        D_B_real_decision = D_B(real_B)\n",
    "        D_B_real_loss = MSE_Loss(D_B_real_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
    "        \n",
    "        fake_B = fake_B_pool.query(fake_B)\n",
    "        \n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        D_B_fake_loss = MSE_Loss(D_B_fake_decision, Variable(torch.zeros(D_B_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # Back propagation\n",
    "        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "        D_B_optimizer.zero_grad()\n",
    "        D_B_loss.backward()\n",
    "        D_B_optimizer.step()\n",
    "        \n",
    "        # ------------------------ Print -----------------------------\n",
    "        # loss values\n",
    "        D_A_losses.append(D_A_loss.item())\n",
    "        D_B_losses.append(D_B_loss.item())\n",
    "        G_A_losses.append(G_A_loss.item())\n",
    "        G_B_losses.append(G_B_loss.item())\n",
    "        cycle_A_losses.append(cycle_A_loss.item())\n",
    "        cycle_B_losses.append(cycle_B_loss.item())\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print('Epoch [%d/%d], Step [%d/%d], D_A_loss: %.4f, D_B_loss: %.4f, G_A_loss: %.4f, G_B_loss: %.4f'\n",
    "                  % (epoch+1, params['num_epochs'], i+1, len(train_data_loader_A), D_A_loss.item(), D_B_loss.item(), G_A_loss.item(), G_B_loss.item()))\n",
    "            \n",
    "        step += 1\n",
    "        \n",
    "    D_A_avg_loss = torch.mean(torch.FloatTensor(D_A_losses))\n",
    "    D_B_avg_loss = torch.mean(torch.FloatTensor(D_B_losses))\n",
    "    G_A_avg_loss = torch.mean(torch.FloatTensor(G_A_losses))\n",
    "    G_B_avg_loss = torch.mean(torch.FloatTensor(G_B_losses))\n",
    "    cycle_A_avg_loss = torch.mean(torch.FloatTensor(cycle_A_losses))\n",
    "    cycle_B_avg_loss = torch.mean(torch.FloatTensor(cycle_B_losses))\n",
    "\n",
    "    # avg loss values for plot\n",
    "    D_A_avg_losses.append(D_A_avg_loss.item())\n",
    "    D_B_avg_losses.append(D_B_avg_loss.item())\n",
    "    G_A_avg_losses.append(G_A_avg_loss.item())\n",
    "    G_B_avg_losses.append(G_B_avg_loss.item())\n",
    "    cycle_A_avg_losses.append(cycle_A_avg_loss.item())\n",
    "    cycle_B_avg_losses.append(cycle_B_avg_loss.item())\n",
    "    \n",
    "    # Show result for test image\n",
    "    test_real_A = test_real_A_data.cuda()\n",
    "    test_fake_B = G_A(test_real_A)\n",
    "    test_recon_A = G_B(test_fake_B)\n",
    "\n",
    "    test_real_B = test_real_B_data.cuda()\n",
    "    test_fake_A = G_B(test_real_B)\n",
    "    test_recon_B = G_A(test_fake_A)\n",
    "\n",
    "    plot_train_result([test_real_A, test_real_B], [test_fake_B, test_fake_A], [test_recon_A, test_recon_B],\n",
    "                            epoch, save=True)\n",
    "\n",
    "all_losses = pd.DataFrame()\n",
    "all_losses['D_A_avg_losses'] = D_A_avg_losses\n",
    "all_losses['D_B_avg_losses'] = D_B_avg_losses\n",
    "all_losses['G_A_avg_losses'] = G_A_avg_losses\n",
    "all_losses['G_B_avg_losses'] = G_B_avg_losses\n",
    "all_losses['cycle_A_avg_losses'] = cycle_A_avg_losses\n",
    "all_losses['cycle_B_avg_losses'] = cycle_B_avg_losses\n",
    "all_losses.to_csv('avg_losses',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
